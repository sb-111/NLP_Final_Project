{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess done\n",
      "[['요리왕-성북구청점', '오랜', '만', '완두콩', '옥수수', '들다', '짜장면', '먹다', '보다', '배달', '무척', '이나', '빠르다', '짬뽕', '국물', '서비스', '오니', '야식', '시키다', '때', '정말', '딱이다', '근데', '제', '입맛', '엔', '조금', '짜다'], ['요리왕-성북구청점', '배달', '초', '스피드', '개맛', '있다'], ['요리왕-성북구청점', '잡채', '밥', '첨', '시키다', '맛있다'], ['요리왕-성북구청점', '맛', '양', '까지', '다', '최고', '예요'], ['요리왕-성북구청점', '맛있다', '먹다'], ['요리왕-성북구청점', '맛있다', '자다', '먹다'], ['요리왕-성북구청점', '아니다', '제', '도착', '문자', '해달라다', '체크', '놧', '늘다', '시간', '넘다', '지나다', '안', '오다', '레', '문자', '혹시', '나', '해', '서문', '밖에', '보', '니깐', '음식', '오다', '이미', '음식', '춥다', '다', '식', '엇', '곱다', '차갑다', '상태', '네', '요', '문자', '하', '나', '써주다', '뭐', '어렵다', '참나', '다시다', '안', '시키다', '먹다'], ['요리왕-성북구청점', '너무', '맛있다'], ['요리왕-성북구청점', '탕수육', '맛있다', '짬뽕', '짜장', '제', '입맛', '에는', '좀', '짜다', '느껴지다', '네', '요담', '엔', '싱겁다', '요청', '드리다'], ['요리왕-성북구청점', '인분', '배달', '되다', '곳', '중', '제일', '맛있다', '여기', '서', '만', '시키다', '구', '요'], ['요리왕-성북구청점', '아침', '일찍', '인분', '배달', '돼다', '넘다', '좋다'], ['요리왕-성북구청점', '여기', '볶음밥', '직접', '볶다', '듯', '여', '맛있다'], ['요리왕-성북구청점', '배달', '빠르다', '가격', '착하다', '맛', '굿'], ['요리왕-성북구청점', '내용물', '푸다', '짐', '하고', '맛있다'], ['요리왕-성북구청점', '이름', '값', '하', '집', '그냥', '요리', '게다가', '새벽', '까지', '너무', '좋다'], ['요리왕-성북구청점', '오늘', '탕', '짜다', '최악', '이다', '탕수육', '역', '냄새', '물론', '이고', '질겨', '서', '씹다', '못', '가끔', '땅짬', '땅', '짜다', '면', '배달', '먹다', '그동안', '고', '기', '냄새', '좀', '나다', '먹다', '오늘', '탕수육', '점', '먹다', '다', '버리다'], ['요리왕-성북구청점', '맛있다', '자다', '먹다'], ['요리왕-성북구청점', '굿'], ['요리왕-성북구청점', '맛있다', '먹다'], ['요리왕-성북구청점', '맛있다', '자다', '먹다'], ['요리왕-성북구청점', '맛', '잇다'], ['요리왕-성북구청점', '기스면', '국물', '아쭈', '깨끗하다'], ['요리왕-성북구청점', '너', '어어', '어', '무', '맛있다', '자다', '먹다', 'ㅋㅋ'], ['요리왕-성북구청점', '맛있다', '배달', '빨르다'], ['요리왕-성북구청점', '맛', '환상', '이다', '최고'], ['요리왕-성북구청점', '저', '짜장면', '먹다', '싶다', '때', '항상', '여기', '주문', '진짜', '맛있다'], ['요리왕-성북구청점', '맛있다', '맛있다', '맛있다'], ['요리왕-성북구청점', '배달', '개', '빠르다', '존맛', '탱', 'ㄱㄱ'], ['요리왕-성북구청점', '여기', '맵다', '짜장', '너무', '좋다', '완전', '제', '스타일'], ['요리왕-성북구청점', '빠르다', '배달', '완전', '강추'], ['요리왕-성북구청점', '맛있다'], ['요리왕-성북구청점', '맛있다', '먹다'], ['요리왕-성북구청점', '십분', '만에', '오다', '맛있다'], ['요리왕-성북구청점', '양도', '많다', '맛있다', '딱', '이렇다', '돈까스', '먹다', '음', '또', '시키다'], ['요리왕-성북구청점', '맛있다', '자다', '먹다'], ['요리왕-성북구청점', '푸다', '지다', '맛있다', '먹다', '사진', '못', '찍다', '죄송하다'], ['요리왕-성북구청점', '주', '방장', '님', '바뀌다', '보다', '자장면', '면발', '얇다', '너무나', '좋다', '읍니', '다', '때', '까지', '요리왕', '먹다', '보다', '면', '중', '최고', '이다', 'ㅎ', '짬뽕', '국물', '은은하다', '깊다', '맛', '일품', '이네', '요', '요리왕', '다시', '자주', '용하다', '되다', '같다', 'ㅎ'], ['요리왕-성북구청점', '맛있다', '양', '넉넉하다', '감사하다'], ['요리왕-성북구청점', '년', '전', '피시방', '자주', '시키다', '먹다', '직장인', '돼다', '시키다', '먹다', '감회', '새롭다', '앞', '으로도', '자다', '부탁드리다'], ['요리왕-성북구청점', '이번', '에도', '너무', '맛있다', '만들다', '맛있다', '먹다'], ['요리왕-성북구청점', '맛있다', '먹다'], ['요리왕-성북구청점', '탕수육', '두툼', '하고', '짬뽕', '그렇다', '너무', '맛있다', '자주', '주문', '먹다', '되다'], ['요리왕-성북구청점', '먹다'], ['요리왕-성북구청점', '친구', '홈', '오피스', '집들이', '짐', '옮기다', '파티', '준비', '너무', '배', '고프다', '한식', '일식', '중식', '주문', '음식', '중', '요리왕', '배송', '제일', '빨리', '오다', '굿굿', '사하다', '역시', '자장면', 'ㅋㅋㅋ', '탕슉', '자장', '짬뽕', '세트', '군', '만두', '서비스', '땡큐', '덕분', '맛있다', '먹다'], ['요리왕-성북구청점', 'ㅎㅎ', '맛있다', '자다', '먹다', '먹다', '중간', '찍다', '번창'], ['요리왕-성북구청점', '맛있다', '너무', '빨리', '다', '먹음'], ['요리왕-성북구청점', '맛있다', '자다', '먹다'], ['요리왕-성북구청점', '정말', '맛있다', '자다', '먹다', 'ㅋㅋ'], ['요리왕-성북구청점', '국물', '남다', '자다', '보관', '끓이다', '밥', '말아먹다', '맛', '나다', '먹다', '음식', '전체', '적', '다', '맛있다', '자주', '배달', '시키다'], ['요리왕-성북구청점', '짜장면', '맛있다', '자다', '먹다'], ['요리왕-성북구청점', '먹다', '배다', '피', '죽', '뻔', '살', '았', '네', '요'], ['요리왕-성북구청점', '먹다'], ['요리왕-성북구청점', '맛있다', '얼', '크다', '아니다', '엄청', '맵다', '맵다', '먹다', '펴다', '엄청', '맵', '네', '용', '좀', '만', '덜맵', '게', '해도', '되다', '같다'], ['요리왕-성북구청점', '자다', '먹다', 'ㅠㅠㅠ', '엄청', '맛있다', 'ㅠㅠㅠ', '감사하다', '앞', '으로도', '열심히', '주문'], ['요리왕-성북구청점', '배달', '빠르다', '양', '엄청', '많다'], ['요리왕-성북구청점', '배달', '빠르다', '맛있다'], ['요리왕-성북구청점', '새벽', '너무', '먹다', '싶다', '시키다', '생각', '보다', '매다', 'ㅋㅋㅋ', '자다', '먹다'], ['요리왕-성북구청점', '오랜', '만', '시키다', '맛있다', '먹다'], ['요리왕-성북구청점', '맛', '상당하다', '깔끔하다', '탕수육', '튀김', '정도', '적당하다', '바삭', '쫄깃', '하고', '맛있다', '먹다'], ['요리왕-성북구청점', '먹다'], ['요리왕-성북구청점', '양도', '많다', '정말', '맛있다', '먹다', '탕수육', '진짜', '맛집', '이네', '요'], ['요리왕-성북구청점', '다', '먹다', '버리다', '사진', '없다', '여기다', '그냥', '맛있다'], ['요리왕-성북구청점', '간짜장', '상당하다', '만족하다'], ['요리왕-성북구청점', '일주일', '만에', '또', '주문', '자다', '먹다', 'ㅋㅋ'], ['요리왕-성북구청점', '너무', '든든하다', '자다', '먹다', 'ㅠㅠㅠ'], ['요리왕-성북구청점', '맛있다', '맛있다', '따다', '봉'], ['요리왕-성북구청점', '요리', '보고', '조리', '보아', '요리왕'], ['요리왕-성북구청점', '맛있다', '먹다', 'ㅎ'], ['요리왕-성북구청점', '항상', '배달', '빠르다', '맛있다', '먹다'], ['요리왕-성북구청점', '가끔', '시키다', '먹다', '요리왕', '좋다'], ['요리왕-성북구청점', '아침', '일찍', '배달', '돼다', '좋다'], ['요리왕-성북구청점', '배달', '빠르다', '맛있다'], ['요리왕-성북구청점', '받다', '감사하다'], ['요리왕-성북구청점', '해산물', '많다', '탕수육', '튀김', '옷', '적당하다', '맛있다', '먹다'], ['요리왕-성북구청점', '맛', '나다', '먹다', 'ㅎㅎ'], ['요리왕-성북구청점', '얼큰하다', '해장', '잘햤습니', '다'], ['요리왕-성북구청점', '맛있다', '자다', '먹다'], ['요리왕-성북구청점', '맛있다', '자다', '먹다'], ['요리왕-성북구청점', '양', '오', '마오', '마', '해', '요', '아주아주', '역시', '성북구', '최고', '중식', '맛집'], ['요리왕-성북구청점', '배달', '빠르다', '너무', '맛있다'], ['요리왕-성북구청점', '볶음밥', '야무지다', '맛있다'], ['요리왕-성북구청점', '녀무', '맛있다', '먹다', '감사하다'], ['요리왕-성북구청점', '맛있다', '맛있다', '맛있다'], ['요리왕-성북구청점', '맛있다', '먹다'], ['요리왕-성북구청점', '맛있다', '먹다'], ['요리왕-성북구청점', '맛있다', '먹다'], ['요리왕-성북구청점', '맛있다', '빠르다'], ['요리왕-성북구청점', '맛있다', '맛있다', '맛있다'], ['요리왕-성북구청점', '맛있다', '맛있다', '맛있다'], ['요리왕-성북구청점', '짬뽕', '국물', '따로', '주다', '탕수육', '튀김', '두께', '딱좋다', '맛있다'], ['요리왕-성북구청점', '맛있다', '배달', '비도', '없다', '좋다'], ['요리왕-성북구청점', '양도', '많다', '맛있다'], ['요리왕-성북구청점', '맛있다', '양도', '많다', 'ㅎ'], ['요리왕-성북구청점', '잘먹엇습돠'], ['요리왕-성북구청점', '안', '내용물', '정말', '많다', '맛', '죽이다'], ['요리왕-성북구청점', '간짜장', '맛있다'], ['요리왕-성북구청점', '가족', '맛있다', '먹다'], ['요리왕-성북구청점', '오늘', '조금', '튀김', '딱딱하다'], ['요리왕-성북구청점', '오래전', '부터', '단골', '지다', '늘', '현금', '으로만', '시키다', '곳', '인데', '요', '기요', '뜨다', '시키다', '보다', '탕복', '같다', '소스', '따로', '달라', '고', '말', '안해', '따로', '주시', '면', '좋다', '같다', '탕수육', '갈색', '빛나다', '바짝', '튀기다', '좋다', '같다', '튀김', '옷', '밝다', '빛깔', '나', '면서', '튀김', '옷', '사이사이', '검은색', '조금씩', '비치다', '색', '알다', '그리고', '가끔', '고기', '돼지', '노리다', '나다', '섞다', '그렇다', '씹히다', '못', '먹다', '핏물좀', '빼다', '간판', '요리왕', '이다', '요리왕', '답', '게', '자부심', '가지', '고', '노력', '좀', '부탁드리다'], ['요리왕-성북구청점', '맛있다'], ['요리왕-성북구청점', '너무', '맛있다']]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from gensim.models.fasttext import FastText, load_facebook_vectors, load_facebook_model\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "def preprocess_korean_text(text, stop_words=[]):\n",
    "    okt = Okt()\n",
    "    \n",
    "    # 형태소 분석을 통한 토큰화\n",
    "    words = okt.morphs(text, norm=True, stem=True) # 정규화 처리\n",
    "    \n",
    "    # 불용어 제거\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return words\n",
    "\n",
    "def process_csv_file(csv_path, stop_words=[]):\n",
    "    new_data = []\n",
    "    \n",
    "    df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "    # if 'reviews' in df.columns:\n",
    "    #     # for text in df['reviews']:\n",
    "    #     #     # 추가적인 전처리 작업 (예: 특수 문자 제거, 숫자 제거 등)\n",
    "    #     #     text = re.sub(r'[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z\\s]', '', text)\n",
    "    #     #     \n",
    "    #     #     # 전처리된 문장을 추가 데이터에 포함\n",
    "    #     #     tokens = preprocess_korean_text(text, stop_words)\n",
    "    #     #     new_data.append(tokens)\n",
    "    #     for name, text in zip(df['name'], df['reviews']):\n",
    "    #         # 추가적인 전처리 작업 (예: 특수 문자 제거, 숫자 제거 등)\n",
    "    #         text = re.sub(r'[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z\\s]', '', text)\n",
    "    #         \n",
    "    #         # 전처리된 문장과 매장명을 추가 데이터에 포함\n",
    "    #         processed_text = preprocess_korean_text(text, stop_words)\n",
    "    #         processed_text.insert(0, name)\n",
    "    #         new_data.append(processed_text)\n",
    "    new_data = [\n",
    "            [\n",
    "                name,\n",
    "                # clean_mark,\n",
    "                # delivery_cost, least_cost, \n",
    "                # review_event, \n",
    "                # taste_star,quantity_star, delivery_star,\n",
    "                *preprocess_korean_text(re.sub(r'[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z\\s]', '', text), stop_words)\n",
    "            ]\n",
    "        # for name, text, clean_mark, delivery_cost, least_cost, review_event, taste_star, quantity_star, delivery_star in zip(\n",
    "        #     df['name'], df['reviews'], df['cleanMark'], df['delivery_cost'], df['least_cost'], df['reviewEvent'], df['taste_star'], df['quantity_star'], df['delivery_star']\n",
    "        # )\n",
    "        for name, text in zip(df['name'], df['reviews'])\n",
    "    ]\n",
    "\n",
    "    return new_data\n",
    "\n",
    "# 새로운 데이터 파일 경로\n",
    "input_csv_file_name = \"reviews_converted_data_tagging.csv\"\n",
    "csv_file_path = f'../ReviewData/{input_csv_file_name}'\n",
    "\n",
    "# 불용어 리스트 (필요에 따라 추가)\n",
    "stop_words = ['의','가', '에','들','는','잘','걍','과','도','를','으로','한','하다','!','?','<','>','(',')','[',']','|','#','.', '이','은','는','을','에','에서','로']\n",
    "\n",
    "# CSV 파일 처리 및 전처리\n",
    "new_data = process_csv_file(csv_file_path, stop_words)\n",
    "print(\"preprocess done\")\n",
    "print(new_data[0:101])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T04:30:52.783799Z",
     "start_time": "2023-12-12T04:28:38.399074Z"
    }
   },
   "id": "6ffa3865585819a3"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 성공적으로 업데이트되었습니다. 업데이트된 모델 경로: /Users/heojw/Desktop/Workspace/univ/3-2/NaturalLanguageProcessing/TermProject/Preprocess/updated_model_reviews_name.bin\n"
     ]
    }
   ],
   "source": [
    "# # 기존 pre-trained 모델 경로\n",
    "# pretrained_model_path = 'wiki.ko.bin'\n",
    "# \n",
    "# # 모델 로드\n",
    "# # model = load_facebook_vectors(pretrained_model_path)\n",
    "# model = load_facebook_model(pretrained_model_path)\n",
    "# \n",
    "# # 모델 업데이트\n",
    "# model.build_vocab(corpus_iterable=new_data, update=True)\n",
    "# model.train(corpus_iterable=new_data, total_examples=len(new_data), epochs=model.epochs)\n",
    "\n",
    "# 직접 만든 모델\n",
    "model = FastText(sentences=new_data, window=5, min_count=10, workers=4, sg=1, epochs=100)\n",
    "\n",
    "# 업데이트된 모델 저장\n",
    "updated_model_path = f'updated_model_{input_csv_file_name.split(\".\")[0]}.bin'\n",
    "model.save(updated_model_path)\n",
    "\n",
    "# 저장된 모델 경로 출력\n",
    "print(f\"모델이 성공적으로 업데이트되었습니다. 업데이트된 모델 경로: {os.path.abspath(updated_model_path)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T11:40:16.295291Z",
     "start_time": "2023-12-11T11:39:28.871853Z"
    }
   },
   "id": "9b34f531ab32ca61"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9d6714cf45d5e661"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "# 저장한 모델 불러오기\n",
    "model = FastText.load(f'./{updated_model_path}')\n",
    "\n",
    "def find_similar_words(word, topn=10):\n",
    "    try:\n",
    "        # 입력한 단어와 유사한 단어들을 찾기\n",
    "        similar_words = model.wv.most_similar(word, topn=topn)\n",
    "\n",
    "        # 결과 출력\n",
    "        print(f\"입력한 단어 '{word}'와(과) 유사한 단어들:\")\n",
    "        for similar_word, similarity in similar_words:\n",
    "            print(f\"{similar_word}: {similarity}\")\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"입력한 단어 '{word}'는 모델의 어휘에 없습니다.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T11:40:47.028885Z",
     "start_time": "2023-12-11T11:40:46.331347Z"
    }
   },
   "id": "7d499cf0883628ac"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력한 단어 '교촌치킨'와(과) 유사한 단어들:\n",
      "교촌: 0.7284786701202393\n",
      "동대문: 0.5651504397392273\n",
      "교촌치킨-동대문1호점: 0.557990312576294\n",
      "콤보: 0.5523183345794678\n",
      "허니: 0.5053131580352783\n",
      "지: 0.48752468824386597\n",
      "치킨: 0.48023173213005066\n",
      "골드: 0.47006797790527344\n",
      "코바: 0.46466726064682007\n",
      "허니콤: 0.4635542035102844\n"
     ]
    }
   ],
   "source": [
    "# 사용자로부터 단어 입력 받기\n",
    "user_input = input(\"단어를 입력하세요: \")\n",
    "\n",
    "# 유사한 단어 찾기 및 출력\n",
    "find_similar_words(user_input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T11:41:14.216651Z",
     "start_time": "2023-12-11T11:41:12.371156Z"
    }
   },
   "id": "8abadf88855f5ec7"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.231*\"배달\" + 0.126*\"빠르다\" + 0.125*\"맛있다\" + 0.116*\"감사하다\" + 0.053*\"오다\"')\n",
      "(1, '0.102*\"밥\" + 0.080*\"고\" + 0.068*\"좋다\" + 0.055*\"주다\" + 0.054*\"새벽\"')\n",
      "(2, '0.210*\"정말\" + 0.091*\"님\" + 0.076*\"사장\" + 0.073*\"맛있다\" + 0.050*\"짱\"')\n",
      "(3, '0.097*\"보다\" + 0.089*\"먹다\" + 0.067*\"맛있다\" + 0.055*\"시키다\" + 0.053*\"처음\"')\n",
      "(4, '0.355*\"너무\" + 0.181*\"맛있다\" + 0.107*\"진짜\" + 0.059*\"먹다\" + 0.045*\"사진\"')\n",
      "(5, '0.103*\"서비스\" + 0.095*\"짬뽕\" + 0.088*\"맛\" + 0.087*\"먹다\" + 0.083*\"나다\"')\n",
      "(6, '0.157*\"요\" + 0.075*\"맛\" + 0.074*\"나\" + 0.048*\"순\" + 0.043*\"치킨\"')\n",
      "(7, '0.061*\"같다\" + 0.038*\"것\" + 0.034*\"없다\" + 0.027*\"보다\" + 0.023*\"되다\"')\n",
      "(8, '0.064*\"리뷰\" + 0.051*\"안\" + 0.046*\"ㅠㅠ\" + 0.032*\"받다\" + 0.026*\"오다\"')\n",
      "(9, '0.077*\"다\" + 0.055*\"아쉽다\" + 0.051*\"좀\" + 0.051*\"조금\" + 0.048*\"맛있다\"')\n",
      "(10, '0.128*\"배달\" + 0.114*\"시간\" + 0.077*\"늦다\" + 0.062*\"오다\" + 0.049*\"분\"')\n",
      "(11, '0.165*\"먹다\" + 0.101*\"시키다\" + 0.080*\"ㅎㅎ\" + 0.076*\"맛있다\" + 0.052*\"여기\"')\n",
      "(12, '0.215*\"좋다\" + 0.154*\"고기\" + 0.087*\"있다\" + 0.082*\"맛\" + 0.034*\"튀김\"')\n",
      "(13, '0.210*\"양\" + 0.125*\"많다\" + 0.067*\"국물\" + 0.064*\"맛있다\" + 0.047*\"비\"')\n",
      "(14, '0.177*\"맛\" + 0.128*\"최고\" + 0.122*\"이다\" + 0.085*\"잇다\" + 0.080*\"넘다\"')\n",
      "(15, '0.191*\"시키다\" + 0.141*\"먹다\" + 0.135*\"또\" + 0.124*\"주문\" + 0.105*\"맛있다\"')\n",
      "(16, '0.084*\"집\" + 0.063*\"곳\" + 0.048*\"맛집\" + 0.045*\"중\" + 0.040*\"드리다\"')\n",
      "(17, '0.084*\"요\" + 0.081*\"푸다\" + 0.075*\"짐\" + 0.069*\"네\" + 0.040*\"양념\"')\n",
      "(18, '0.235*\"양도\" + 0.231*\"많다\" + 0.138*\"맛있다\" + 0.052*\"배달\" + 0.036*\"엄청\"')\n",
      "(19, '0.370*\"먹다\" + 0.300*\"맛있다\" + 0.220*\"자다\" + 0.038*\"항상\" + 0.017*\"있다\"')\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# 예시 리뷰 데이터 (한글)\n",
    "# reviews = [\n",
    "#     \"잡채밥은 첨시켰는데 맛있어요!\",\n",
    "#     \"맛과 양까지 다 최고예요\",\n",
    "#     \"맛있게 잘먹었습니다\",\n",
    "#     \"맛있게 잘 먹었습니다.\",\n",
    "#     \"아니 제가 도착하면 문자해달라고 체크해놧는데한시간 넘게 지나서도 안오길레 문자가 혹시나 해서문밖에 보니깐 음식 와있네요^^이미 음식은 추워서 다 식엇고 차가운상태네요문자하나 써주는게 뭐가 어렵다고 참나다신 안시켜먹을듯 하네요\",\n",
    "#     \"너무 맛있어요！！！！！！！！\"\n",
    "# ]\n",
    "# \n",
    "# # konlpy를 사용하여 명사만 추출하는 전처리 함수 정의\n",
    "# def preprocess(text):\n",
    "#     okt = Okt()\n",
    "#     nouns = okt.nouns(text)\n",
    "#     return nouns\n",
    "# \n",
    "# # 전처리된 텍스트 생성\n",
    "# processed_reviews = [preprocess(review) for review in reviews]\n",
    "processed_reviews = new_data\n",
    "\n",
    "# Gensim을 위한 사전(dictionary)과 코퍼스(corpus) 생성\n",
    "dictionary = corpora.Dictionary(processed_reviews)\n",
    "corpus = [dictionary.doc2bow(text) for text in processed_reviews]\n",
    "\n",
    "# LDA 모델 훈련\n",
    "lda_model = LdaModel(corpus, num_topics=20, id2word=dictionary, passes=15)\n",
    "\n",
    "# 토픽 출력\n",
    "topics = lda_model.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T04:32:23.207957Z",
     "start_time": "2023-12-12T04:31:04.078500Z"
    }
   },
   "id": "24306ecb3ffa653a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(preprocess_korean_text(re\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms]\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, review), stop_words))\n\u001B[1;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../ReviewData/reviews_converted_data_tagging.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreviews\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mreviews\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpandas_review_preprocessing\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m df\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[0;32m~/anaconda3/envs/NLP_PROJECT/lib/python3.10/site-packages/pandas/core/series.py:4760\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[1;32m   4625\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4626\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4627\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4632\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4633\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4634\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4635\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4636\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4751\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4752\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   4753\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4754\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4755\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4756\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4757\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4758\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4759\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m-> 4760\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/NLP_PROJECT/lib/python3.10/site-packages/pandas/core/apply.py:1207\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1204\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[1;32m   1206\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[0;32m-> 1207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/NLP_PROJECT/lib/python3.10/site-packages/pandas/core/apply.py:1287\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1281\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[1;32m   1282\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[1;32m   1283\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[1;32m   1284\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[1;32m   1285\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[1;32m   1286\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1287\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1288\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[1;32m   1289\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1291\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1292\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1293\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1294\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/anaconda3/envs/NLP_PROJECT/lib/python3.10/site-packages/pandas/core/base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[0;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[1;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[0;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/NLP_PROJECT/lib/python3.10/site-packages/pandas/core/algorithms.py:1814\u001B[0m, in \u001B[0;36mmap_array\u001B[0;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m   1812\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   1813\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1814\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1815\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1816\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[1;32m   1817\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[1;32m   1818\u001B[0m     )\n",
      "File \u001B[0;32mlib.pyx:2917\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Cell \u001B[0;32mIn[15], line 2\u001B[0m, in \u001B[0;36mpandas_review_preprocessing\u001B[0;34m(review)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpandas_review_preprocessing\u001B[39m(review : \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[43mpreprocess_korean_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43ms]\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreview\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop_words\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[0;32mIn[3], line 12\u001B[0m, in \u001B[0;36mpreprocess_korean_text\u001B[0;34m(text, stop_words)\u001B[0m\n\u001B[1;32m      9\u001B[0m okt \u001B[38;5;241m=\u001B[39m Okt()\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# 형태소 분석을 통한 토큰화\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m words \u001B[38;5;241m=\u001B[39m \u001B[43mokt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmorphs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstem\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# 정규화 처리\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# 불용어 제거\u001B[39;00m\n\u001B[1;32m     15\u001B[0m words \u001B[38;5;241m=\u001B[39m [word \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m words \u001B[38;5;28;01mif\u001B[39;00m word \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m stop_words]\n",
      "File \u001B[0;32m~/anaconda3/envs/NLP_PROJECT/lib/python3.10/site-packages/konlpy/tag/_okt.py:89\u001B[0m, in \u001B[0;36mOkt.morphs\u001B[0;34m(self, phrase, norm, stem)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmorphs\u001B[39m(\u001B[38;5;28mself\u001B[39m, phrase, norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, stem\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m     87\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Parse phrase to morphemes.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 89\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [s \u001B[38;5;28;01mfor\u001B[39;00m s, t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpos\u001B[49m\u001B[43m(\u001B[49m\u001B[43mphrase\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstem\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstem\u001B[49m\u001B[43m)\u001B[49m]\n",
      "File \u001B[0;32m~/anaconda3/envs/NLP_PROJECT/lib/python3.10/site-packages/konlpy/tag/_okt.py:71\u001B[0m, in \u001B[0;36mOkt.pos\u001B[0;34m(self, phrase, norm, stem, join)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"POS tagger.\u001B[39;00m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;124;03mIn contrast to other classes in this subpackage,\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;124;03mthis POS tagger doesn't have a `flatten` option,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;124;03m:param join: If True, returns joined sets of morph and tag.\u001B[39;00m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     69\u001B[0m validate_phrase_inputs(phrase)\n\u001B[0;32m---> 71\u001B[0m tokens \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjki\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mphrase\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mjpype\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjava\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlang\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBoolean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnorm\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mjpype\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjava\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlang\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBoolean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstem\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtoArray()\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m join:\n\u001B[1;32m     76\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [t \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m tokens]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def pandas_review_preprocessing(review : str):\n",
    "    return \" \".join(preprocess_korean_text(re.sub(r'[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z\\s]', '', review), stop_words))\n",
    "    \n",
    "df = pd.read_csv(\"../ReviewData/reviews_converted_data_tagging.csv\")\n",
    "df['reviews'] = df['reviews'].apply(pandas_review_preprocessing)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T09:06:40.162972Z",
     "start_time": "2023-12-12T09:06:37.323904Z"
    }
   },
   "id": "52eeec2c778a701"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../ReviewData/reviews_converted_data_tagging.csv\")\n",
    "df.drop(['Unnamed: 0', 'reviewEvent'], axis=1, inplace=True)\n",
    "# CSV 파일로 저장, 인덱스 제외 및 인코딩 지정\n",
    "df.to_csv('../ReviewData/reviews_last.csv', index=False, encoding='utf-8-sig')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T09:10:15.824462Z",
     "start_time": "2023-12-12T09:10:15.570309Z"
    }
   },
   "id": "aa3fc7bd6181e263"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ee7a439a44797e88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
